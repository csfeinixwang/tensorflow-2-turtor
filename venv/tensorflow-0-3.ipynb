{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'utf-8'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "#coding=utf8\n",
    "import sys\n",
    "sys.getdefaultencoding()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 标准的人工智能项目按照如下步骤进行\n",
    "| 1 准备数据\n",
    "| 2 准备模型\n",
    "| 3 训练模型\n",
    "| 4 评估模型\n",
    "| 5 使用模型 \n",
    "| 6 保存模型\n",
    "## "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[b'the', b'and', b'a', b'of', b'to', b'is', b'in', b'it', b'i', b'this', b'that', b'was', b'as', b'for', b'with', b'movie', b'but', b'film', b'on', b'not', b'you', b'his', b'are', b'have', b'be', b'he', b'one', b'its', b'at', b'all', b'by', b'an', b'they', b'from', b'who', b'so', b'like', b'her', b'just', b'or', b'about', b'has', b'if', b'out', b'some', b'there', b'what', b'good', b'more', b'when', b'very', b'she', b'even', b'my', b'no', b'would', b'up', b'time', b'only', b'which', b'story', b'really', b'their', b'were', b'had', b'see', b'can', b'me', b'than', b'we', b'much', b'well', b'get', b'been', b'will', b'into', b'people', b'also', b'other', b'do', b'bad', b'because', b'great', b'first', b'how', b'him', b'most', b'dont', b'made', b'then', b'them', b'films', b'movies', b'way', b'make', b'could', b'too', b'any', b'after', b'characters']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models,layers,preprocessing,optimizers,losses,metrics\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "import re,string\n",
    "\n",
    "# 1 准备样本\n",
    "train_data_path=\"./datasets/imdb/train.csv\"\n",
    "test_data_path=\"././datasets/imdb/test.csv\"\n",
    "# 最高频1w词\n",
    "Max_Words =10000\n",
    "# 保留样本长度 200个词\n",
    "Max_Len=200\n",
    "Batch_Size=20\n",
    "\n",
    "# 构建管道\n",
    "\n",
    "def split_line(line):\n",
    "    arr = tf.strings.split(line,\"\\t\")\n",
    "    label=tf.expand_dims(tf.cast(tf.strings.to_number(arr[0]),tf.int32),axis=0)\n",
    "    text = tf.expand_dims(arr[1],axis=0)\n",
    "    return (text,label)\n",
    "\n",
    "ds_train_raw = tf.data.TextLineDataset(filenames=[train_data_path]) \\\n",
    "    .map(split_line,num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n",
    "    .shuffle(buffer_size=1000).batch(Batch_Size) \\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_test_raw = tf.data.TextLineDataset(filenames=[test_data_path]) \\\n",
    "    .map(split_line,num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n",
    "    .batch(Batch_Size) \\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "## 清理文本\n",
    "def clean_text(text):\n",
    "    lowercase =tf.strings.lower(text)\n",
    "    stripped_html =tf.strings.regex_replace(lowercase,'<br />',' ')\n",
    "    # 清理所有标点符号\n",
    "    clean_punctuation =tf.strings.regex_replace(stripped_html,'[%s]' % re.escape(string.punctuation),'')\n",
    "    return  clean_punctuation\n",
    "\n",
    "# 构建向量层\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=clean_text,\n",
    "    split = 'whitespace',\n",
    "    max_tokens=Max_Words-1,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=Max_Len\n",
    ")\n",
    "\n",
    "ds_text =ds_train_raw.map(lambda text,label:text)\n",
    "vectorize_layer.adapt(ds_text)\n",
    "print(vectorize_layer.get_vocabulary()[0:100])\n",
    "\n",
    "ds_train =ds_train_raw.map(lambda text,label:(vectorize_layer(text),label)) \\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test_raw.map(lambda text,label:(vectorize_layer(text),label)) \\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"cnn_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  70000     \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv1D)              multiple                  576       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv1D)              multiple                  4224      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  6145      \n",
      "=================================================================\n",
      "Total params: 80,945\n",
      "Trainable params: 80,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## 2 定义模型\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "class CnnModel(models.Model):\n",
    "    def __init__(self):\n",
    "        super(CnnModel,self).__init__()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.embedding = layers.Embedding(Max_Words,7,input_length=Max_Len)\n",
    "        self.conv_1 =layers.Conv1D(16,kernel_size=5,name=\"conv_1\",activation=\"relu\")\n",
    "        self.pool =layers.MaxPool1D()\n",
    "        self.conv_2 =layers.Conv1D(128,kernel_size=2,name=\"conv_2\",activation=\"relu\")\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense = layers.Dense(1, activation=\"sigmoid\")\n",
    "        super(CnnModel, self).build(input_shape)\n",
    "        \n",
    "    def call(self,x):\n",
    "        x=self.embedding(x)\n",
    "        x=self.conv_1(x)\n",
    "        x=self.pool(x)\n",
    "        x=self.conv_2(x)\n",
    "        x=self.pool(x)\n",
    "        x=self.flatten(x)\n",
    "        x=self.dense(x)\n",
    "        return(x)\n",
    "\n",
    "model = CnnModel()\n",
    "model.build(input_shape =(None,Max_Len))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "========================================================================23:34:59\r\n",
      "Epoch=1,Loss:0.244055256,Accuracy:0.9032,Valid Loss:0.308990479,Valid Accuracy0.8768\r\n",
      "\r\n",
      "========================================================================23:35:06\r\n",
      "Epoch=2,Loss:0.173470512,Accuracy:0.9345,Valid Loss:0.345653564,Valid Accuracy0.8728\r\n",
      "\r\n",
      "========================================================================23:35:13\r\n",
      "Epoch=3,Loss:0.115960017,Accuracy:0.95715,Valid Loss:0.500443101,Valid Accuracy0.848\r\n",
      "\r\n",
      "========================================================================23:35:21\r\n",
      "Epoch=4,Loss:0.0687751696,Accuracy:0.97625,Valid Loss:0.56670624,Valid Accuracy0.8602\r\n",
      "\r\n",
      "========================================================================23:35:28\r\n",
      "Epoch=5,Loss:0.0359254554,Accuracy:0.9884,Valid Loss:0.772485256,Valid Accuracy0.8528\r\n",
      "\r\n",
      "========================================================================23:35:37\r\n",
      "Epoch=6,Loss:0.017658487,Accuracy:0.9951,Valid Loss:1.0004921,Valid Accuracy0.8546\r\n",
      "\r\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 训练模型\n",
    "## 装饰器 提前调用计算图\n",
    "\n",
    "# 打印出来 时间\n",
    "@tf.function\n",
    "def printbar():\n",
    "    ts =tf.timestamp()\n",
    "    today_ts = ts%(24*60*60)\n",
    "    \n",
    "    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n",
    "    minute = tf.cast((today_ts%3600)//60,tf.int32)\n",
    "    second =tf.cast(tf.floor(today_ts%60),tf.int32)\n",
    "    \n",
    "    def timeformat(m):\n",
    "        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n",
    "            return (tf.strings.format(\"0{}\",m))\n",
    "        else:\n",
    "            return (tf.strings.format(\"{}\",m))\n",
    "    timesstring = tf.strings.join([timeformat(hour),timeformat(minute),timeformat(second)],separator=\":\")\n",
    "    tf.print(\"=========\"*8,end=\"\")\n",
    "    tf.print(timesstring)\n",
    "    \n",
    "#定义超参数\n",
    "optimizer = optimizers.Nadam()\n",
    "\n",
    "loss_func = losses.BinaryCrossentropy()\n",
    "\n",
    "train_loss=metrics.Mean(name='train_loss')\n",
    "\n",
    "train_metric =metrics.BinaryAccuracy(name=\"train_accuracy\")\n",
    "\n",
    "valid_loss =metrics.Mean(name='valid_loss')\n",
    "\n",
    "valid_metric =metrics.BinaryAccuracy(name='valid_accuracy')\n",
    "\n",
    "\n",
    "#定义训练步骤\n",
    "\n",
    "@tf.function\n",
    "def train_step(model,features,labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions =model(features,training =True)\n",
    "        loss =loss_func(labels,predictions)\n",
    "    gradients = tape.gradient(loss,model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
    "    \n",
    "    train_loss.update_state(loss)\n",
    "    train_metric.update_state(labels,predictions)\n",
    "\n",
    "# 定义验证\n",
    "@tf.function\n",
    "def valid_step(model,features,labels):\n",
    "    predictions =model(features,training = False)\n",
    "    batch_loss =loss_func(labels,predictions)\n",
    "    valid_loss.update_state(batch_loss)\n",
    "    valid_metric.update_state(labels,predictions)\n",
    "    \n",
    "    \n",
    "# 定义训练模型\n",
    "\n",
    "def train_model(model,ds_train,ds_valid,epochs):\n",
    "    for epoch in tf.range(1,epochs+1):\n",
    "        for features,labels in ds_train:\n",
    "            train_step(model,features,labels)\n",
    "            \n",
    "        for features,labels in ds_test:\n",
    "            valid_step(model,features,labels)\n",
    "            \n",
    "        logs ='Epoch={},Loss:{},Accuracy:{},Valid Loss:{},Valid Accuracy{}'\n",
    "        \n",
    "        if epoch%1==0:\n",
    "            printbar()\n",
    "            tf.print(tf.strings.format(logs,\n",
    "                    (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))\n",
    "            tf.print(\"\")\n",
    "        \n",
    "        train_loss.reset_states()\n",
    "        valid_loss.reset_states()\n",
    "        train_metric.reset_states()\n",
    "        valid_metric.reset_states()\n",
    "        \n",
    "train_model(model,ds_train,ds_test,epochs=6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Valid Loss:1.0004921,Valid Accuracy0.8546\r\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#评估模型\n",
    "def evluate_model(model,ds_valid):\n",
    "    for features,labels in ds_valid:\n",
    "        valid_step(model,features,labels)\n",
    "    logs=\"Valid Loss:{},Valid Accuracy{}\"\n",
    "    tf.print(tf.strings.format(logs,(valid_loss.result(),valid_metric.result())))\n",
    "    \n",
    "    valid_loss.reset_states()\n",
    "    train_metric.reset_states()\n",
    "    valid_metric.reset_states()\n",
    "    \n",
    "evluate_model(model,ds_test)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.7925186],\n       [0.9999998],\n       [0.9999987],\n       ...,\n       [0.9631697],\n       [0.484992 ],\n       [1.       ]], dtype=float32)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 20
    }
   ],
   "source": [
    "#使用模型 \n",
    "model.predict(ds_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[7.9251921e-01]\n",
      " [9.9999988e-01]\n",
      " [9.9999857e-01]\n",
      " [1.5074768e-10]\n",
      " [1.6863579e-01]\n",
      " [2.3242046e-06]\n",
      " [1.4598606e-07]\n",
      " [1.9180906e-09]\n",
      " [9.9995601e-01]\n",
      " [9.9995553e-01]\n",
      " [9.9999988e-01]\n",
      " [9.8068851e-01]\n",
      " [1.4484363e-09]\n",
      " [9.9951124e-01]\n",
      " [1.4443553e-10]\n",
      " [2.1784449e-01]\n",
      " [2.5157800e-05]\n",
      " [7.5942245e-03]\n",
      " [5.3736067e-06]\n",
      " [9.9998558e-01]], shape=(20, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[4.6119094e-04]\n",
      " [1.0000000e+00]\n",
      " [9.9983931e-01]\n",
      " [3.1419568e-06]\n",
      " [9.9999958e-01]\n",
      " [9.9954975e-01]\n",
      " [9.0569365e-01]\n",
      " [1.0739243e-01]\n",
      " [9.9835253e-01]\n",
      " [9.9999964e-01]\n",
      " [5.5930644e-01]\n",
      " [9.9998367e-01]\n",
      " [9.9950373e-01]\n",
      " [9.9999940e-01]\n",
      " [1.0000000e+00]\n",
      " [9.6882761e-14]\n",
      " [9.9349147e-01]\n",
      " [6.3158069e-08]\n",
      " [3.8814569e-06]\n",
      " [7.7965548e-03]], shape=(20, 1), dtype=float32)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for x_test,_ in ds_test.take(2):\n",
    "    print(model(x_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./datasets/keras_models/0-3\\assets\n",
      "saved model\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "array([[0.7925186],\n       [0.9999998],\n       [0.9999987],\n       ...,\n       [0.9631697],\n       [0.484992 ],\n       [1.       ]], dtype=float32)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 23
    }
   ],
   "source": [
    "#保存模型\n",
    "model.save('./datasets/keras_models/0-3',save_format='tf')\n",
    "print('saved model')\n",
    "\n",
    "model_loaded = tf.keras.models.load_model('././datasets/keras_models/0-3')\n",
    "\n",
    "model_loaded.predict(ds_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}